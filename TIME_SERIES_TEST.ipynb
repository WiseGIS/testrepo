{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### ARIMA Prediction Process"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The pyodbc library has been imported!\n"
                }
            ],
            "source": "import numpy as np, pandas as pd\nimport pyodbc\nprint('The pyodbc library has been imported!')\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##### Check the versions of key python libraries"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "scipy: 1.5.2\nnumpy: 1.19.2\nmatplotlib: 3.3.2\npandas: 1.1.3\nstatsmodels: 0.12.2\nsklearn: 0.23.1\n"
                }
            ],
            "source": "#scipy\nimport scipy\nprint ('scipy: %s' % scipy.__version__)\n\n#numpy\nimport numpy\nprint ('numpy: %s' % numpy.__version__)\n\n#matplotlib\nimport matplotlib\nprint ('matplotlib: %s' % matplotlib.__version__)\n\n#pandas\nimport pandas\nprint ('pandas: %s' % pandas.__version__)\n\n#statsmodels\nimport statsmodels\nprint ('statsmodels: %s' % statsmodels.__version__)\n\n#sklearn\nimport sklearn\nprint ('sklearn: %s' % sklearn.__version__)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Data downloaded and read into a dataframe!\n"
                }
            ],
            "source": "# Windows Authentication to SQL Server\nconx_string = \"driver={SQL Server}; server=ENG010206\\SQLEXPRESS01; database=master; Trucursor = conx.cursor();\"\n\n\nprint('Data downloaded and read into a dataframe!')\n\n#for row in cursor:\n    #print(row)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Query is now active!\n"
                }
            ],
            "source": "# Build the container for the data\nquery = \"SELECT * FROM [master].[dbo].[MMPS_210_FLOW_HOURLY]\"\nprint('Query is now active!')"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The database connect is now active!\n"
                }
            ],
            "source": "# Create a CONNECTION using the connection string and pyodbc.connect()\nconx = pyodbc.connect(conx_string);\nprint('The database connect is now active!')"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The cursor has been created!\n"
                }
            ],
            "source": "cursor = conx.cursor();\nprint('The cursor has been created!')"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Run the query!\n"
                }
            ],
            "source": "cursor.execute(query);\nprint('Run the query!')"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Store the results in a dataframe!\n"
                }
            ],
            "source": "data = cursor.fetchall()\nprint('Store the results in a dataframe!')"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "['measurement_id', 'trend_data_time', 'trend_data_interval', 'trend_data_flags', 'trend_data_min', 'trend_data_avg', 'trend_data_max', 'Facility_Name', 'Site_Name', 'measurement_name', 'MSTN', '_copynum']\n"
                }
            ],
            "source": "columns = [row.column_name for row in cursor.columns(table='MMPS_210_FLOW_HOURLY')]\nprint(columns)"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "      trend_data_time  trend_data_avg\n0 2019-07-30 09:00:00     2674.166748\n1 2019-07-30 10:00:00     2676.354248\n2 2019-07-30 11:00:00     2553.333252\n3 2019-07-30 12:00:00     2519.687500\n4 2019-07-30 13:00:00     2538.437500\n"
                }
            ],
            "source": "# query = \"SELECT Facility_Name, Site_Name, measurement_id, trend_data_time, trend_data_avg FROM [master].[dbo].[MMPS_120_FLOW];\"\nquery = \"SELECT trend_data_time, trend_data_avg FROM [master].[dbo].[MMPS_210_FLOW_HOURLY];\"\ndf = pd.read_sql(query, conx)\nprint(df.head(5))"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "      trend_data_time  trend_data_avg\n0 2019-07-30 09:00:00     2674.166748\n1 2019-07-30 10:00:00     2676.354248\n2 2019-07-30 11:00:00     2553.333252\n3 2019-07-30 12:00:00     2519.687500\n4 2019-07-30 13:00:00     2538.437500\n"
                }
            ],
            "source": "series = pd.read_sql(query, conx,)\nprint(df.head(5))"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "#def datetime_to_int(df):\n    #return int(df.trend_data_time(\"%Y%m%d%H%M%S\"))"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "<class 'pandas.core.frame.DataFrame'>\n"
                }
            ],
            "source": "print(type(df))"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "33878\n"
                }
            ],
            "source": "print(series.size)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# RESET"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Setting the working directory"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": "import os"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'C:\\\\Users\\\\cwise.HRSD-NT\\\\OneDrive - HRSD\\\\DATA_SCIENCE\\\\Python\\\\Nansemond'"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "os. getcwd() "
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "os.chdir('/Users/cwise.HRSD-NT/OneDrive - HRSD/DATA_SCIENCE/Python/WORKING')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Descriptive Statistics"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "                     trend_data_avg\ntrend_data_time                    \n2019-07-30 09:00:00       2674.1667\n2019-07-30 10:00:00       2676.3542\n2019-07-30 11:00:00       2553.3333\n2019-07-30 12:00:00       2519.6875\n2019-07-30 13:00:00       2538.4375\n"
                }
            ],
            "source": "from pandas import read_csv\nfrom pandas import DataFrame\n\nseries = read_csv('dbo.MMPS_210_FLOW_HOURLY.csv', header=0, index_col=0, parse_dates=True)\nprint(series.head())"
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "                     trend_data_avg\ntrend_data_time                    \n2019-07-30 09:00:00       2674.1667\n2019-07-30 10:00:00       2676.3542\n2019-07-30 11:00:00       2553.3333\n2019-07-30 12:00:00       2519.6875\n2019-07-30 13:00:00       2538.4375\n"
                }
            ],
            "source": "from pandas import read_csv\nfrom pandas import DataFrame\n\nseries = read_csv('dbo.MMPS_210_FLOW_HOURLY.csv', header=0, index_col=0, parse_dates=True)\nprint(series.head())"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##### <span style='color:Yellow'> header=0 is to specify the header information at row 0.</span>\n##### <span style='color:Yellow'>parse_dates=True The function is provided a hint that data in the first column contains dates that need to be parsed.\n##### <span style='color:Yellow'>index_col=0 the first column contains the index information for the time series.\n##### <span style='color:Yellow'>squeeze=True is a hint that one data column contains one data column and that we are interested in a series and not a dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "       trend_data_avg\ncount    16939.000000\nmean      2551.547827\nstd        586.203412\nmin        518.645800\n25%       2139.791650\n50%       2636.458300\n75%       2936.458300\nmax       6955.000000\n16939\n"
                }
            ],
            "source": "from pandas import read_csv\nfrom pandas import DataFrame\n\nseries = read_csv('dbo.MMPS_210_FLOW_HOURLY.csv', header=0, index_col=0, parse_dates=True)\nprint(series.describe())\nprint(series.size)"
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "2674.1667\n"
                }
            ],
            "source": "from pandas import read_csv\nseries = read_csv('dbo.MMPS_210_FLOW_HOURLY.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\nprint(series['2019-07-30 09:00:00'])"
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [],
            "source": "from pandas import read_csv\nseries = read_csv('dbo.MMPS_210_FLOW_HOURLY.csv', header=0, index_col=0, parse_dates=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Feature Engineering"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##### <span style='color:Yellow'>The goal of feature engineering is to provide strong and ideally simple relationships between new input features and the output feaures for the supervised learning algorithm to model."
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "                     trend_data_avg\ntrend_data_time                    \n2019-07-30 09:00:00       2674.1667\n2019-07-30 10:00:00       2676.3542\n2019-07-30 11:00:00       2553.3333\n2019-07-30 12:00:00       2519.6875\n2019-07-30 13:00:00       2538.4375\n"
                }
            ],
            "source": "print(series.head(5))"
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "trend_data_time\n2019-07-30 09:00:00    2674.1667\n2019-07-30 10:00:00    2676.3542\n2019-07-30 11:00:00    2553.3333\n2019-07-30 12:00:00    2519.6875\n2019-07-30 13:00:00    2538.4375\nName: trend_data_avg, dtype: float64\n"
                }
            ],
            "source": "from pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\n\nseries = read_csv('dbo.MMPS_210_FLOW_HOURLY.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n\nflows = DataFrame(series.values)\ndataframe=concat([flows.shift(1),flows],axis=1)\ndataframe.columns=['t','t+1']\nprint(series.head(5))"
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "trend_data_time\n2019-07-30 09:00:00    2674.1667\n2019-07-30 10:00:00    2676.3542\n2019-07-30 11:00:00    2553.3333\n2019-07-30 12:00:00    2519.6875\n2019-07-30 13:00:00    2538.4375\nName: trend_data_avg, dtype: float64\n"
                }
            ],
            "source": "from pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\n\nseries = read_csv('dbo.MMPS_210_FLOW_HOURLY.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n\nflows = DataFrame(series.values)\ndataframe=concat([flows.shift(3), flows.shift(2), flows.shift(1), flows],axis=1)\ndataframe.columns=['t-2','t-1','t','t+1']\nprint(series.head(5))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}